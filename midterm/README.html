<!DOCTYPE html>
<html>
<head>
<title>README.md</title>
<meta http-equiv="Content-type" content="text/html;charset=UTF-8">

<style>
/* https://github.com/microsoft/vscode/blob/master/extensions/markdown-language-features/media/markdown.css */
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

body {
	font-family: var(--vscode-markdown-font-family, -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif);
	font-size: var(--vscode-markdown-font-size, 14px);
	padding: 0 26px;
	line-height: var(--vscode-markdown-line-height, 22px);
	word-wrap: break-word;
}

#code-csp-warning {
	position: fixed;
	top: 0;
	right: 0;
	color: white;
	margin: 16px;
	text-align: center;
	font-size: 12px;
	font-family: sans-serif;
	background-color:#444444;
	cursor: pointer;
	padding: 6px;
	box-shadow: 1px 1px 1px rgba(0,0,0,.25);
}

#code-csp-warning:hover {
	text-decoration: none;
	background-color:#007acc;
	box-shadow: 2px 2px 2px rgba(0,0,0,.25);
}

body.scrollBeyondLastLine {
	margin-bottom: calc(100vh - 22px);
}

body.showEditorSelection .code-line {
	position: relative;
}

body.showEditorSelection .code-active-line:before,
body.showEditorSelection .code-line:hover:before {
	content: "";
	display: block;
	position: absolute;
	top: 0;
	left: -12px;
	height: 100%;
}

body.showEditorSelection li.code-active-line:before,
body.showEditorSelection li.code-line:hover:before {
	left: -30px;
}

.vscode-light.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(0, 0, 0, 0.15);
}

.vscode-light.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(0, 0, 0, 0.40);
}

.vscode-light.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-dark.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 255, 255, 0.4);
}

.vscode-dark.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 255, 255, 0.60);
}

.vscode-dark.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-high-contrast.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 160, 0, 0.7);
}

.vscode-high-contrast.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 160, 0, 1);
}

.vscode-high-contrast.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

img {
	max-width: 100%;
	max-height: 100%;
}

a {
	text-decoration: none;
}

a:hover {
	text-decoration: underline;
}

a:focus,
input:focus,
select:focus,
textarea:focus {
	outline: 1px solid -webkit-focus-ring-color;
	outline-offset: -1px;
}

hr {
	border: 0;
	height: 2px;
	border-bottom: 2px solid;
}

h1 {
	padding-bottom: 0.3em;
	line-height: 1.2;
	border-bottom-width: 1px;
	border-bottom-style: solid;
}

h1, h2, h3 {
	font-weight: normal;
}

table {
	border-collapse: collapse;
}

table > thead > tr > th {
	text-align: left;
	border-bottom: 1px solid;
}

table > thead > tr > th,
table > thead > tr > td,
table > tbody > tr > th,
table > tbody > tr > td {
	padding: 5px 10px;
}

table > tbody > tr + tr > td {
	border-top: 1px solid;
}

blockquote {
	margin: 0 7px 0 5px;
	padding: 0 16px 0 10px;
	border-left-width: 5px;
	border-left-style: solid;
}

code {
	font-family: Menlo, Monaco, Consolas, "Droid Sans Mono", "Courier New", monospace, "Droid Sans Fallback";
	font-size: 1em;
	line-height: 1.357em;
}

body.wordWrap pre {
	white-space: pre-wrap;
}

pre:not(.hljs),
pre.hljs code > div {
	padding: 16px;
	border-radius: 3px;
	overflow: auto;
}

pre code {
	color: var(--vscode-editor-foreground);
	tab-size: 4;
}

/** Theming */

.vscode-light pre {
	background-color: rgba(220, 220, 220, 0.4);
}

.vscode-dark pre {
	background-color: rgba(10, 10, 10, 0.4);
}

.vscode-high-contrast pre {
	background-color: rgb(0, 0, 0);
}

.vscode-high-contrast h1 {
	border-color: rgb(0, 0, 0);
}

.vscode-light table > thead > tr > th {
	border-color: rgba(0, 0, 0, 0.69);
}

.vscode-dark table > thead > tr > th {
	border-color: rgba(255, 255, 255, 0.69);
}

.vscode-light h1,
.vscode-light hr,
.vscode-light table > tbody > tr + tr > td {
	border-color: rgba(0, 0, 0, 0.18);
}

.vscode-dark h1,
.vscode-dark hr,
.vscode-dark table > tbody > tr + tr > td {
	border-color: rgba(255, 255, 255, 0.18);
}

</style>

<style>
/* Tomorrow Theme */
/* http://jmblog.github.com/color-themes-for-google-code-highlightjs */
/* Original theme - https://github.com/chriskempson/tomorrow-theme */

/* Tomorrow Comment */
.hljs-comment,
.hljs-quote {
	color: #8e908c;
}

/* Tomorrow Red */
.hljs-variable,
.hljs-template-variable,
.hljs-tag,
.hljs-name,
.hljs-selector-id,
.hljs-selector-class,
.hljs-regexp,
.hljs-deletion {
	color: #c82829;
}

/* Tomorrow Orange */
.hljs-number,
.hljs-built_in,
.hljs-builtin-name,
.hljs-literal,
.hljs-type,
.hljs-params,
.hljs-meta,
.hljs-link {
	color: #f5871f;
}

/* Tomorrow Yellow */
.hljs-attribute {
	color: #eab700;
}

/* Tomorrow Green */
.hljs-string,
.hljs-symbol,
.hljs-bullet,
.hljs-addition {
	color: #718c00;
}

/* Tomorrow Blue */
.hljs-title,
.hljs-section {
	color: #4271ae;
}

/* Tomorrow Purple */
.hljs-keyword,
.hljs-selector-tag {
	color: #8959a8;
}

.hljs {
	display: block;
	overflow-x: auto;
	color: #4d4d4c;
	padding: 0.5em;
}

.hljs-emphasis {
	font-style: italic;
}

.hljs-strong {
	font-weight: bold;
}
</style>

<style>
/*
 * Markdown PDF CSS
 */

 body {
	font-family: -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif, "Meiryo";
	padding: 0 12px;
}

pre {
	background-color: #f8f8f8;
	border: 1px solid #cccccc;
	border-radius: 3px;
	overflow-x: auto;
	white-space: pre-wrap;
	overflow-wrap: break-word;
}

pre:not(.hljs) {
	padding: 23px;
	line-height: 19px;
}

blockquote {
	background: rgba(127, 127, 127, 0.1);
	border-color: rgba(0, 122, 204, 0.5);
}

.emoji {
	height: 1.4em;
}

code {
	font-size: 14px;
	line-height: 19px;
}

/* for inline code */
:not(pre):not(.hljs) > code {
	color: #C9AE75; /* Change the old color so it seems less like an error */
	font-size: inherit;
}

/* Page Break : use <div class="page"/> to insert page break
-------------------------------------------------------- */
.page {
	page-break-after: always;
}

</style>

<script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
</head>
<body>
  <script>
    mermaid.initialize({
      startOnLoad: true,
      theme: document.body.classList.contains('vscode-dark') || document.body.classList.contains('vscode-high-contrast')
          ? 'dark'
          : 'default'
    });
  </script>
<h1 id="probability-and-stochastic-processes">probability and stochastic processes</h1>
<p><a href="https://www.youtube.com/watch?v=vfqPpai_9jI&amp;list=PLUl4u3cNGP60hI9ATjSFgLZpbNJ7myAg6&amp;index=50">link</a></p>
<h2 id="1-experiments-models-and-probabilities">1.  experiments, models, and probabilities</h2>
<p><strong>theorem 1.1</strong> demorgan's law related all three basic operations $ (A \cup B)^c = (A^c \cap B^c) \ $</p>
<p><strong>theorem 1.2</strong> for mutually exclusive events $A_1$ and $A_2$, $ P[A_1 \cup A_2] = P[A_1] + P[A_2] $</p>
<p><strong>theorem 1.3</strong> If $ A = A_1 \cup A_2 \cup \cdots \cup A_m $ and $ A_i \cap A_j = \emptyset $ for all $ i \neq j $, then</p>
<p>$$ P[A] = \sum_{i=1}^m P[A_i] $$</p>
<p><strong>theorem 1.4</strong> The probability measure $P[.]$ is a function that satisfies the following properties:</p>
<ol>
<li>
<p>$ P[\emptyset] = 0 \ $</p>
</li>
<li>
<p>$ P[A^c] = 1 - P[A] \ $</p>
</li>
<li>
<p>For any A and B (not necessarily mutually exclusive), $ P[A \cup B] = P[A] + P[B] - P[A \cap B] $</p>
</li>
<li>
<p>If $ A \subset B,$ $then$ $P[A] \leq P[B] $</p>
</li>
</ol>
<p><strong>Theorem 1.5</strong> The probability of an event $ B = {s_1, s_2, \cdots, s_m} $ is the sum of the probabilities of the outcomes contained in the event:</p>
<p>$$ P[B] = \sum_{i=1}^m P[{s_i}] $$</p>
<p><strong>theorem 1.6</strong> For an experiment with sample space $ S = {s_1, s_2, \cdots, s_n} $ in which each outcomes $s_i$ is equally likely,</p>
<p>$$ P[{s_i}] = \frac{1}{n}  \space \space \space  1 ≤ i ≤ n  $$</p>
<p><strong>theroem 1.7</strong> A conditional probability measure $ P[A|B] $ has the following properties that correspond to the axioms of probability:</p>
<p>Axiom 1: $ P[A|B] \geq 0 $</p>
<p>Axiom 2: $ P[B|B] = 1 $</p>
<p>Axiom 3: If $ A = A_1 \cup A_2 \cup \cdots \cup A_m $ and $ A_i \cap A_j = \emptyset $ for all $ i \neq j $, then</p>
<p>$$ P[A|B] = P[A_1|B] + P[A_2|B] + \cdots + P[A_m|B] $$</p>
<p><strong>Theorem 1.8</strong>   For a partition $ B = {B_1, B_2, \cdots, B_m} $ and any event $A$ in the sample space, let $ C_i = A \cap B_i $ For $ i ≠ j $, the events $ C_i $ and $ C_j $ are mutually exclusive and $ A = C_1 \cup C_2 \cup \cdots $</p>
<p><strong>Theorem 1.9</strong>  For any event $ A $ and partition $ {B_1, B_2, \cdots, B_m} $</p>
<p>$$ P[A] = \sum_{i=1}^m P[A \cap B_i $$</p>
<p><strong>Theorem 1.10</strong>  Law of total probability</p>
<p>For a partition {$ { B_1, B_2, \cdots, B_m } $} with $ P[B_i] &gt; 0 $ for all $ i $,</p>
<p>$$ P[A] = \sum_{i=1}^m P[A|B_i] P[B_i] $$</p>
<p><strong>Theorem 1.11</strong>  Bayes' theorem</p>
<p>$$ P[B|A] = \frac{P[A|B] P[B]}{P[A]} $$</p>
<p><strong>Definition 1.1 Outcome</strong> An outcome of an experiment is a possible result of the experiment.</p>
<p><strong>Definition 1.2 Sample space</strong> The sample space of an experiment is the finest-grain, mutually exclusive, collectively exhaustive set of all possible outcomes of the experiment.</p>
<p><strong>Definition 1.3 Event</strong> An event is a subset of the sample space.</p>
<p><strong>Definition 1.4 Axioms of Probability</strong> A probability measure $ P[.] $ is a function that maps events in the sample spacce to real numbers such that</p>
<p><strong>Axiom 1</strong> For any event $ A $, $ P[A] \geq 0 $</p>
<p><strong>Axiom 2</strong> $ P[S] = 1 $</p>
<p><strong>Axiom 3</strong> For any countable collection $A_1, A_2, \cdots $ of mutually exclusive events,</p>
<p>$$ P[A_1 \cup A_2 \cup \cdots] = P[A_1] + P[A_2] + \cdots $$</p>
<p><strong>Definition 1.5 Conditional probability</strong> The conditional probability of an event $ A $ given the occurance of the event B is</p>
<p>$$ P[A|B] = {P[AB] \over P[B]}$$</p>
<p>Conditional probability is defined only when $ P[B] &gt; 0 $.</p>
<p><strong>Definition 1.6 Two independent events</strong> Two events $ A $ and $ B $ are independent if</p>
<p>$$ P[AB] = P[A]P[B] $$</p>
<p><strong>Definition 1.7 Three Independent Events</strong> $ A_1, A_2, A_3 $ are mutually exclusive and independent if and only if</p>
<p>(a) $A_1$ and $A_2 $ are independent</p>
<p>(b) $A_2$ and $A_3$ are independent</p>
<p>(c) $A_1$ and $A_3$ are independent</p>
<p>(d) $P[A_1 \cap A_2 \cap A_3] = P[A_1]P[A_2]P[A_3]$</p>
<p><strong>Definition 1.8 More than Two Independent Events</strong></p>
<p>If $n ≥ 3$ events $A_1, A_2, \cdots, A_n$ are mutually independent if an only if</p>
<p>(a) all collections of $n - 1$ events chosen from $A_1, A_2, \cdots, A_n$ are mutually independent,</p>
<p>(b) $P[A_1 \cap A_2 \cap \cdots \cap A_n] = P[A_1]P[A_2] \cdots P[A_n]$</p>
<h2 id="2-sequential-experiments">2.  Sequential Experiments</h2>
<p><strong>Theorem 2.1</strong></p>
<p>An experiment consists of two subexperiments.  If one subexperiment has $k$ outcomes and the other has $n$ outcomes, then the experiment has $kn$ outcomes.</p>
<p><strong>Theorem 2.2</strong></p>
<p>The number of k-permutations of $n$ distinguishable objects is</p>
<p>$$ {n \choose k} = {(n)_k \over k! } = {n! \over {k! (n - k)!}}$$</p>
<p><strong>Theorem 2.4</strong></p>
<p>Given $m$ distinguishable objects, there are $m^n$ ways to choose ith replacement an ordered sample of n objects.</p>
<p><strong>Theorem 2.5</strong></p>
<p>For $n$ repitions of a subexperiment with sample space $S_sub = {s_1, s_2, \cdots, s_m-1}$, the sample space $S$ of the sequential experiment has $m^n$ outcomes.</p>
<p><strong>Theorem 2.6</strong></p>
<p>The number of observation sequences for $n$ subexperiments with sample space $S = {0,1}$ with $0$ appearing $n_0$ times and $1$ appearing $n_1 = n - n_0$ times is $n \choose n_1$.</p>
<p><strong>Theorem 2.7</strong></p>
<p>For n reptitions of a subexperiment with sample space $S = {s_0, s_1, \cdots, s_m-1}$, the number of length $n = n_0 + n_1 + \cdots + n_{m-1}$ observation sequences with $s_i$ appearing $n_i$ times is</p>
<p>$$ {n \choose n_0, n_1, \cdots, n_{m-1}} = {n! \over {n_0! n_1! \cdots n_{m-1}!}} $$</p>
<p><strong>Theorem 2.8</strong></p>
<p>The probability of $n_0$ failures and $n_1$ successes in $n = n_0 + n_1$ independent trials is</p>
<p>$$ P[E_{n_0, n_1}] = {n \choose n_1} (1-p)^{n-n_1} p^n_1 = {n \choose n_0} (1-p)^{n_0} p^{n - n_0} $$</p>
<p><strong>Theorem 2.9</strong></p>
<p>A subexperiment has sample space $S = {s_0, s_1, \cdots, s_m-1}$ with $P[s_i] = p_i$ for $n = n_0 + n_1 + \cdots + n_{m-1}$ independent trials, the probability of $n_i$ occurrences of $s_i$, $i = 0, 1, \cdots, m-1$ is</p>
<p>$$ P[E_{n_0, n_1, \cdots, n_{m-1}}] = {n \choose n_0, n_1, \cdots, n_{m-1}} p_0^{n_0} p_1^{n_1} \cdots p_{m-1}^{n_{m-1}} $$</p>
<p><strong>Definition 2.1 $n$ choose $k$</strong></p>
<p>For an integer $n ≥ 0$, we define</p>
<p>$$ {n \choose k} = \begin{cases}
{n! \over {k! (n - k)!}} &amp; k = 0, 1, \dots, n, \
0 &amp; \text{otherwise} \  \end{cases} $$</p>
<p><strong>Definition 2.2 Multinomial coefficient</strong>  $\space \text{For an integer n ≥ 0, we define }$</p>
<p>$${n \choose n_0, n_1, \dots, n_{m-1}} = {n! \over {n_0! n_1! \cdots n_{m-1}!}}$$</p>
<h2 id="3-discrete-random-variables">3. Discrete Random Variables</h2>
<p><strong>Theorem 3.1</strong></p>
<p>$\text{For a discrete random variable X with PMF} P_X(x), \text{and range} \space S_x: $</p>
<p>$\text{(a) For any x,} \space P_X(x) ≥ 0$</p>
<p>$\text{(b) } \sum_{x \in S_x} P_X(x) = 1$</p>
<p>$\text{(c) For any event} $ $B \subset S_x, \space \text{The probability that X is in the set B is }$</p>
<p>$$P[B] = \sum_{x \in B} P_X(x)$$</p>
<p><strong>Theorem 3.2</strong></p>
<p>$\text{For any discrete random variable X with range} \space S_x = { x_1, x_2, \dots }  \space \text{satisfying} \space x_1 ≤ x_2 ≤ \dots $,</p>
<p>$\text{(a) } F_X=(-\infty) = 0 \space \text{and} \space F_X(\infty) = 1 $</p>
<p>$\text{(b) For all } x' ≥ x, F_X(x') ≥ F_X(x) $</p>
<p>$\text{(c) For all } x' &gt; x, F_X(x') &gt; F_X(x) $</p>
<p>$\text{(d) } F_X(x) = F_X(x_i) \text{for all x such that } x_i ≤ x ≤ x_{i+1} $</p>
<p><strong>Theorem 3.3</strong></p>
<p>$ \text{For all b &gt; a, } F_X(b) - F_X(a) = P[a &lt; X ≤ b] $</p>
<p><strong>Theorem 3.4</strong></p>
<p><input type="checkbox" id="checkbox0" checked="true"><label for="checkbox0">= p $</label></p>
<p><strong>Theorem 3.5</strong></p>
<p><input type="checkbox" id="checkbox1" checked="true"><label for="checkbox1">= 1/p} $</label></p>
<p><strong>Theorem 3.6</strong></p>
<p>$ \text{(a) For the binomial (n, p) random variable X of Definition 3.6} $</p>
<p><input type="checkbox" id="checkbox2" checked="true"><label for="checkbox2">= np \space $$</label></p>
<p>$ \text{(b) For the Pascal (k, p) random variable X of Definition 3.7} $</p>
<p><input type="checkbox" id="checkbox3" checked="true"><label for="checkbox3">= k/p $$</label></p>
<p>$ \text{(c) For the discrete uniform (k, l) random variable X of Definition 3.8} $</p>
<p><input type="checkbox" id="checkbox4" checked="true"><label for="checkbox4">= \frac{k + l}{2} $$</label></p>
<p><strong>Theorem 3.8</strong></p>
<p>$ \text{Perfom n Bernoulli trials.  In each trial, let the probability of success be } {\alpha} / n, \text{where } {\alpha} &gt; 0 \text{is a constant and } n &gt;\alpha.$</p>
<p>$\text{  Let the random variable } K_n \text{ be the number of successes in the n trials.  As } n \rightarrow \infty, P_{K_n}(k) \text{ converges to the PMF of a Poisson } (\alpha) \text{random variable. }$</p>
<p><strong>Theorem 3.9</strong></p>
<p>$ \text{For a discrete random variable X, the PMF of Y = g(X) is}$</p>
<p>$$ P_Y(y) = \sum_{x: g(x) = y} P_X(x) $$</p>
<p><strong>Theorem 3.10</strong></p>
<p>$ \text{Given a random variable X with PMF } P_X(x), \text{ and the derived random variable} Y = g(x), \text{ the expected value of Y is }$</p>
<p>$$ E[Y] = \mu_Y = \sum_{x \in S_x} g(x) P_X(x)  $$</p>
<p><strong>Theorem 3.11</strong></p>
<p>$ \text{For any random variable X, } $</p>
<p>$$ E[X - \mu_{X}] = 0 $$</p>
<p><strong>Theorem 3.12</strong></p>
<p>$ \text{For any random variable X, }$</p>
<p><input type="checkbox" id="checkbox5" checked="true"><label for="checkbox5">+ b $$</label></p>
<p><strong>Theorem 3.13</strong></p>
<p>$ \text{In the absence of observations, the minimum mean square error estimate random variable X is} $</p>
<p><input type="checkbox" id="checkbox6" checked="true"><label for="checkbox6">$$</label></p>
<p><strong>Theorem 3.14</strong></p>
<p><input type="checkbox" id="checkbox7" checked="true"><label for="checkbox7">= E[X^2] - \mu^2_X = E[X^2] - (E[X])^2 $$</label></p>
<p><strong>Theorem 3.15</strong></p>
<p><input type="checkbox" id="checkbox8" checked="true"><label for="checkbox8">$$</label></p>
<p><strong>Theorem 3.16</strong></p>
<p><input type="checkbox" id="checkbox9" checked="true"><label for="checkbox9">= p(1-p) $</label></p>
<p><input type="checkbox" id="checkbox10" checked="true"><label for="checkbox10">= ({1-p})/{p^2} $</label></p>
<p><input type="checkbox" id="checkbox11" checked="true"><label for="checkbox11">= np(1 - p) $</label></p>
<p><input type="checkbox" id="checkbox12" checked="true"><label for="checkbox12">= k(1 - p)/p^2 $</label></p>
<p><input type="checkbox" id="checkbox13" checked="true"><label for="checkbox13">= \alpha $</label></p>
<p><input type="checkbox" id="checkbox14" checked="true"><label for="checkbox14">= (l - k)(l - k + 2)/12 $</label></p>
<p><strong>Definition 3.1 Random Variable</strong></p>
<p>$\text{A random variable consists of an experiment with a probability measure P[.] defined on a sample space S and a function that assigns a real number to each outcome in the sample spacce of the experiment.}$</p>

</body>
</html>
